{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T11:52:18.991349Z",
     "start_time": "2020-06-15T11:52:18.987327Z"
    }
   },
   "source": [
    "### Recognize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:45.704205Z",
     "start_time": "2020-06-16T16:25:39.880786Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import seaborn as sns\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing \n",
    "\n",
    "\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #显示中文标签\n",
    "plt.rcParams['axes.unicode_minus']=False   #这两行需要手动设置\n",
    "# plot图片风格\n",
    "plt.style.use('fivethirtyeight')\n",
    "# pandas最大打印列数\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pandas最大打印行数\n",
    "pd.set_option('display.max_rows', 50)\n",
    "# 设置随机数种子\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:48.528339Z",
     "start_time": "2020-06-16T16:25:45.704205Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "data = pd.read_csv('./data/creditcard/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:48.592378Z",
     "start_time": "2020-06-16T16:25:48.528339Z"
    }
   },
   "outputs": [],
   "source": [
    "# 查看基本信息\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一共284806行数据, 并且数据集中没有缺失的数据.\n",
    "\n",
    "打印数据前10行查看一下具体的数据."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:48.640341Z",
     "start_time": "2020-06-16T16:25:48.592378Z"
    }
   },
   "outputs": [],
   "source": [
    "# 打印前10行数据\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上表可以看到的是, 数据一共有31个特征, 并且最后一个class是我们要预测的目标特征.\n",
    "\n",
    "并且, 因为信用卡交易涉及到了用户的隐私, 上述数据用了PCA方法, 对数据进行了特使处理.\n",
    "\n",
    "可以看到, 除了时间, 交易量, 这两个特征以外, 其余的特征都已经被PCA处理过了.\n",
    "\n",
    "下面让我们来看一下target的分布情况."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:48.816442Z",
     "start_time": "2020-06-16T16:25:48.640341Z"
    }
   },
   "outputs": [],
   "source": [
    "# 目标变量饼图\n",
    "def plot_target_pie(target):\n",
    "    labels = 'Not Fraud', 'Fraud'\n",
    "    explode = (0, 0.1)\n",
    "    fig1, ax1 = plt.subplots(figsize = (7,7))\n",
    "    ax1.pie(target, explode=explode, labels=labels, autopct='%.4f%%',\n",
    "            shadow=True, startangle=120)\n",
    "    ax1.axis('equal')\n",
    "    ax1.legend(labels, loc='best')\n",
    "    plt.title('Data Distribution of Target Variable', fontsize='large')\n",
    "    plt.savefig('./credit_figures/类别.png')\n",
    "    plt.show()\n",
    "\n",
    "plot_target_pie(np.array(data['Class'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到类别极端不平衡, 正类样本(欺诈)只占结果的0.1727%\n",
    "\n",
    "接下来, 我们查看一下其他变量的数据分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:49.750590Z",
     "start_time": "2020-06-16T16:25:48.817447Z"
    }
   },
   "outputs": [],
   "source": [
    "### 查看一下交易时间分布与交易量分布(直方图)\n",
    "def plot_hist(labels):\n",
    "    plt.figure(figsize = (12, 6))\n",
    "    color = ['blue', 'darkorange']\n",
    "    for i, label in enumerate(labels, 1):\n",
    "        plt.subplot(1, 2, i)\n",
    "        np_data = data[label]\n",
    "        plt.hist(np_data,bins=100,alpha=0.8,color = color[i-1], edgecolor='none', label = label + ' Frequence')\n",
    "        plt.xlabel(label)\n",
    "        plt.ylabel('Frequence')\n",
    "        plt.legend(loc = 'best')\n",
    "        plt.title(f'Histogram of Transaction {label}', fontsize = 'large')\n",
    "    plt.savefig('./credit_figures/交易量与时间.png')\n",
    "    plt.show()    \n",
    "plot_hist(['Amount', 'Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到, 交易量比较集中, 大额交易有, 但是大额交易少.\n",
    "\n",
    "可以看到交易时间 呈现一个周期的走势, 符合白天交易频繁, 凌晨交易次数减少."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:55.424282Z",
     "start_time": "2020-06-16T16:25:49.750590Z"
    }
   },
   "outputs": [],
   "source": [
    "### heatmap\n",
    "def plot_heatmap(corr_matrix):\n",
    "    plt.figure(figsize = (22, 22))\n",
    "    sns.heatmap(corr_matrix,\n",
    "                 annot=True,\n",
    "                 linewidths=0.2,\n",
    "                 fmt=\".2f\",\n",
    "                 cmap=\"YlGnBu\",\n",
    "               )\n",
    "    plt.savefig('./credit_figures/热力图.png')\n",
    "    plt.show()\n",
    "corr_matrix = data.corr()\n",
    "plot_heatmap(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:55.697501Z",
     "start_time": "2020-06-16T16:25:55.424282Z"
    }
   },
   "outputs": [],
   "source": [
    "# 查看与class 相关性较强的变量\n",
    "class_relative = corr_matrix['Class']\n",
    "def plot_barh(class_relative, labels):\n",
    "    np_labels = np.array(labels[:-1])\n",
    "    np_data = np.array(class_relative)\n",
    "    plt.figure(figsize = (12, 8))\n",
    "    plt.barh(range(len(np_data)-1) ,np_data[:-1],facecolor='tan',height=0.5,edgecolor='r',alpha=0.6,tick_label=np_labels)\n",
    "    plt.xlabel('Variable Correlation')\n",
    "    plt.show()\n",
    "    \n",
    "plot_barh(class_relative, data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T14:20:38.936953Z",
     "start_time": "2020-06-15T14:20:38.930937Z"
    }
   },
   "source": [
    "找出与变量正相关比较大的三个变量\n",
    "\n",
    "V1, V4, V11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:56.381249Z",
     "start_time": "2020-06-16T16:25:55.697501Z"
    }
   },
   "outputs": [],
   "source": [
    "###  V1, V4, V11\n",
    "\n",
    "def plot_box():\n",
    "    f, axes = plt.subplots(ncols=3, figsize=(20,6))\n",
    "    sns.boxplot(x=\"Class\", y=\"V1\", data=data, ax=axes[0])\n",
    "    axes[0].set_title('V1 vs Class Positive Correlation')\n",
    "    sns.boxplot(x=\"Class\", y=\"V4\", data=data,  ax=axes[1])\n",
    "    axes[1].set_title('V4 vs Class Positive Correlation')\n",
    "    sns.boxplot(x=\"Class\", y=\"V11\", data=data,  ax=axes[2])\n",
    "    axes[2].set_title('V11 vs Class Positive Correlation')\n",
    "    plt.savefig('./credit_figures/箱线图.png')\n",
    "    plt.show()\n",
    "    \n",
    "plot_box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从箱线图可以看出, 与变量正相关的数据分布并不相同\n",
    "\n",
    "### UnderSampling\n",
    "\n",
    "使用自编码器来提取特征\n",
    "\n",
    "由于样本并不平衡, 我们对负例进行采样.\n",
    "\n",
    "从负例中随机采样1000个样本."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:56.480165Z",
     "start_time": "2020-06-16T16:25:56.381249Z"
    }
   },
   "outputs": [],
   "source": [
    "not_fraud = data[data['Class'] == 0].sample(1000)\n",
    "fraud = data[data['Class'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到没有明显的边界"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:56.496243Z",
     "start_time": "2020-06-16T16:25:56.480165Z"
    }
   },
   "outputs": [],
   "source": [
    "df = not_fraud.append(fraud).sample(frac=1).reset_index(drop=True)\n",
    "X = df.drop(['Class'], axis = 1).values\n",
    "Y = df[\"Class\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:56.641387Z",
     "start_time": "2020-06-16T16:25:56.496243Z"
    }
   },
   "outputs": [],
   "source": [
    "# 目标变量饼图\n",
    "def plot_target_pie(target):\n",
    "    labels = 'Not Fraud', 'Fraud'\n",
    "    explode = (0, 0.1)\n",
    "    fig1, ax1 = plt.subplots(figsize = (7,7))\n",
    "    ax1.pie(target, explode=explode, labels=labels, autopct='%.4f%%',\n",
    "            shadow=True, startangle=120)\n",
    "    ax1.axis('equal')\n",
    "    ax1.legend(labels, loc='best')\n",
    "    plt.title('Data Distribution of Target Variable', fontsize='large')\n",
    "    plt.savefig('./credit_figures/类别.png')\n",
    "    plt.show()\n",
    "\n",
    "plot_target_pie(np.array(df['Class'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:56.819547Z",
     "start_time": "2020-06-16T16:25:56.641387Z"
    }
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(X.shape[1],))\n",
    "\n",
    "encoded = Dense(100, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoded = Dense(50, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(50, activation='tanh')(encoded)\n",
    "decoded = Dense(100, activation='tanh')(decoded)\n",
    "\n",
    "output_layer = Dense(X.shape[1], activation='relu')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:56.859616Z",
     "start_time": "2020-06-16T16:25:56.819547Z"
    }
   },
   "outputs": [],
   "source": [
    "autoencoder = Model(input_layer, output_layer)\n",
    "autoencoder.compile(optimizer=\"SGD\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:57.068824Z",
     "start_time": "2020-06-16T16:25:56.859616Z"
    }
   },
   "outputs": [],
   "source": [
    "x = data.drop([\"Class\"], axis=1)\n",
    "y = data[\"Class\"].values\n",
    "\n",
    "x_scale = preprocessing.MinMaxScaler().fit_transform(x.values)\n",
    "x_norm, x_fraud = x_scale[y == 0], x_scale[y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:58.254242Z",
     "start_time": "2020-06-16T16:25:57.068824Z"
    }
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(x_norm[0:2000], x_norm[0:2000], \n",
    "                batch_size = 256, epochs = 20, \n",
    "                shuffle = True, validation_split = 0.20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:58.277815Z",
     "start_time": "2020-06-16T16:25:58.254242Z"
    }
   },
   "outputs": [],
   "source": [
    "hidden_representation = Sequential()\n",
    "hidden_representation.add(autoencoder.layers[0])\n",
    "hidden_representation.add(autoencoder.layers[1])\n",
    "hidden_representation.add(autoencoder.layers[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:25:58.351221Z",
     "start_time": "2020-06-16T16:25:58.278929Z"
    }
   },
   "outputs": [],
   "source": [
    "norm_hid_rep = hidden_representation.predict(x_norm[:1000])\n",
    "fraud_hid_rep = hidden_representation.predict(x_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:26:02.715632Z",
     "start_time": "2020-06-16T16:25:58.351221Z"
    }
   },
   "outputs": [],
   "source": [
    "def tsne_plot(x1, y1, name):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    X_t = tsne.fit_transform(x1)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(X_t[np.where(y1 == 0), 0], X_t[np.where(y1 == 0), 1], marker='o', color='darkblue', linewidth='1', alpha=0.8, label='Non Fraud')\n",
    "    plt.scatter(X_t[np.where(y1 == 1), 0], X_t[np.where(y1 == 1), 1], marker='o', color='darkorange', linewidth='1', alpha=0.8, label='Fraud')\n",
    "    plt.title('t-SNE Data Dimensionality Reduction')\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(name)\n",
    "    plt.show()\n",
    "    \n",
    "tsne_plot(X, Y, \"./credit_figures/original.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:26:07.848235Z",
     "start_time": "2020-06-16T16:26:02.715632Z"
    }
   },
   "outputs": [],
   "source": [
    "rep_x = np.append(norm_hid_rep, fraud_hid_rep, axis = 0)\n",
    "y_n = np.zeros(norm_hid_rep.shape[0])\n",
    "y_f = np.ones(fraud_hid_rep.shape[0])\n",
    "rep_y = np.append(y_n, y_f)\n",
    "tsne_plot(rep_x, rep_y, './credit_figures/Autoencoder.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在这个基础上进行分类."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:26:07.927790Z",
     "start_time": "2020-06-16T16:26:07.848235Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(rep_x, rep_y, test_size=0.25)\n",
    "clf = LogisticRegression(solver=\"lbfgs\").fit(train_x, train_y)\n",
    "pred_y = clf.predict(val_x)\n",
    "\n",
    "print (\"Classification Report: \")\n",
    "print (classification_report(val_y, pred_y))\n",
    "\n",
    "print (\"Accuracy Score: \", accuracy_score(val_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:26:08.047824Z",
     "start_time": "2020-06-16T16:26:07.927790Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression' : LogisticRegression(),\n",
    "    'Decision Tree' : DecisionTreeClassifier(),\n",
    "    'AdaBoost' : AdaBoostClassifier(),\n",
    "    'GradientBoost' : GradientBoostingClassifier(),\n",
    "    'RandomForest' : RandomForestClassifier(),\n",
    "    'ETC' : ExtraTreesClassifier(),\n",
    "    'Bag' : BaggingClassifier(),\n",
    "    'XGBoost' : XGBClassifier(),\n",
    "    'SVC' : SVC(),\n",
    "    'KNN' : KNeighborsClassifier(),\n",
    "    'NB' : GaussianNB(),\n",
    "    'QDA' : QuadraticDiscriminantAnalysis(),\n",
    "    'NN' : MLPClassifier(),\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'Logistic Regression' : {},\n",
    "    'Decision Tree' : {},\n",
    "    'AdaBoost' : {},\n",
    "    'GradientBoost' : {},\n",
    "    'RandomForest' : {},\n",
    "    'XGBoost' : {},\n",
    "    'SVC' : {},\n",
    "    'KNN' : {},\n",
    "    'NB' : {},\n",
    "    'ETC' : {},\n",
    "    'Bag' : {},\n",
    "    'QDA' : {},\n",
    "    'NN' : {},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:26:08.071790Z",
     "start_time": "2020-06-16T16:26:08.047824Z"
    }
   },
   "outputs": [],
   "source": [
    "class EstimatorSelectionHelper:\n",
    "    # 初始化, 加载模型以及提前设置的一些超参数\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "        self.best = {}\n",
    "    # 对每个模型的每组超参数都进行交叉验证\n",
    "    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.best[key] = {'score':gs.best_score_,'params':gs.best_params_}\n",
    "            self.grid_searches[key] = gs    \n",
    "    # 对结果进行统计\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            print(k)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]\n",
    "    # 最优超参数.\n",
    "    def best_params(self):\n",
    "        return self.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:26:16.938061Z",
     "start_time": "2020-06-16T16:26:08.071790Z"
    }
   },
   "outputs": [],
   "source": [
    "Helper = EstimatorSelectionHelper(models, params)\n",
    "Helper.fit(train_x, train_y, cv=5)\n",
    "result = Helper.score_summary(sort_by='mean_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分类器性能比较 水平柱状图\n",
    "def plot_performance(performance):\n",
    "\n",
    "    np_labels = np.array(performance['estimator'])[::-1]\n",
    "    np_data = np.array(performance['mean_score'])[::-1]\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(range(len(np_data)), np_data, facecolor='darkorange', height=0.5, edgecolor=None, alpha=0.8,\n",
    "             tick_label=np_labels)\n",
    "    plt.xlabel('Performance (Mean Score)')\n",
    "    plt.title('Performance Compare (Mean Score)')\n",
    "    plt.savefig('./credit_figures/performance_compare.png')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "performance = result[['estimator','mean_score']]\n",
    "print(performance['estimator'])\n",
    "plot_performance(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:26:16.976705Z",
     "start_time": "2020-06-16T16:26:16.938061Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = SVC().fit(train_x, train_y)\n",
    "pred_y = clf.predict(val_x)\n",
    "\n",
    "print (\"Classification Report: \")\n",
    "print (classification_report(val_y, pred_y))\n",
    "\n",
    "print (\"Accuracy Score: \", accuracy_score(val_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T16:26:17.734612Z",
     "start_time": "2020-06-16T16:26:16.977815Z"
    }
   },
   "outputs": [],
   "source": [
    "# learnin cruve\n",
    "from sklearn.model_selection import learning_curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=1, \n",
    "                        train_sizes=np.linspace(.1, 1., 10), verbose=0, plot=True):\n",
    "\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, verbose=verbose)\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(figsize = (10,10))\n",
    "        plt.title(title)\n",
    "        if ylim is not None:\n",
    "            plt.ylim(*ylim)\n",
    "        plt.xlabel(\"Number of Train Samples\")\n",
    "        plt.ylabel(\"Score\")\n",
    "\n",
    "        plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, \n",
    "                         alpha=0.1, color=\"b\")\n",
    "        plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, \n",
    "                         alpha=0.1, color=\"r\")\n",
    "        plt.plot(train_sizes, train_scores_mean, 'o-', color=\"b\", label=\"Score in Train Set\")\n",
    "        plt.plot(train_sizes, test_scores_mean, 'o-', color=\"r\", label=\"Score in Val Set\")\n",
    "    \n",
    "        plt.legend(loc=\"best\")\n",
    "        \n",
    "        plt.draw()\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.show()\n",
    "    \n",
    "    midpoint = ((train_scores_mean[-1] + train_scores_std[-1]) + (test_scores_mean[-1] - test_scores_std[-1])) / 2\n",
    "    diff = (train_scores_mean[-1] + train_scores_std[-1]) - (test_scores_mean[-1] - test_scores_std[-1])\n",
    "    return midpoint, diff\n",
    "\n",
    "plot_learning_curve(SVC(), \"Learning Curve\", train_x, train_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
