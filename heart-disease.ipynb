{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T02:17:40.389594Z",
     "start_time": "2020-05-28T02:17:40.381405Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "### 将数据导入,并且查看数据的基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:40.557767Z",
     "start_time": "2020-05-28T01:52:40.537819Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/heart-disease-uci/heart.csv')\n",
    "#查看一下基本的信息\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:40.570732Z",
     "start_time": "2020-05-28T01:52:40.559762Z"
    }
   },
   "outputs": [],
   "source": [
    "# 没有缺失的数据\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:40.576718Z",
     "start_time": "2020-05-28T01:52:40.571730Z"
    }
   },
   "outputs": [],
   "source": [
    "# 查看一下类别的数目以及种类, 二分类问题, 并且类别比较均衡\n",
    "np.unique(data['target'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:40.688418Z",
     "start_time": "2020-05-28T01:52:40.578712Z"
    }
   },
   "outputs": [],
   "source": [
    "# 绘制类别的饼图\n",
    "data['target'].value_counts().plot(kind='bar')\n",
    "plt.xlabel('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:40.741277Z",
     "start_time": "2020-05-28T01:52:40.689416Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T16:11:14.896818Z",
     "start_time": "2020-05-26T16:11:14.880483Z"
    }
   },
   "source": [
    "### 用直方图画出各个变量的分布情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:42.256134Z",
     "start_time": "2020-05-28T01:52:40.742275Z"
    }
   },
   "outputs": [],
   "source": [
    "data.hist(bins=30,figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类别型变量与Target之间的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:43.004362Z",
     "start_time": "2020-05-28T01:52:42.258130Z"
    }
   },
   "outputs": [],
   "source": [
    "class_vars = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "plt.figure(figsize=(15,15))\n",
    "for i, column in enumerate(class_vars, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    data[data.target == 0][column].value_counts().plot(kind='bar', color='blue', alpha = 0.5, label = 'Have Heart Disease = NO')\n",
    "    data[data.target == 1][column].value_counts().plot(kind='bar', color='red', alpha = 0.5, label = 'Have Heart Disease = YES')\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel(column)\n",
    "\n",
    "\n",
    "# numeric_vars = ['age', 'chol', 'oldpeak', 'thalach', 'trestbps']\n",
    "# plt.figure(figsize=(6.4,4.8), dpi=120)\n",
    "# sns.heatmap(data.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 连续型变量与Target之间的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:43.957912Z",
     "start_time": "2020-05-28T01:52:43.005327Z"
    }
   },
   "outputs": [],
   "source": [
    "continue_vars = ['age', 'chol', 'oldpeak', 'thalach', 'trestbps']\n",
    "plt.figure(figsize=(10,10))\n",
    "for i, column in enumerate(continue_vars, 1):\n",
    "    plt.subplot(3, 3, i)\n",
    "    data[data.target == 0][column].hist(bins=30, color='blue', alpha = 0.5, label = 'Have Heart Disease = NO')\n",
    "    data[data.target == 1][column].hist(bins=30, color='red', alpha = 0.5, label = 'Have Heart Disease = YES')\n",
    "    plt.legend(loc='best',fontsize='x-small')\n",
    "    plt.xlabel(column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:44.582631Z",
     "start_time": "2020-05-28T01:52:43.958874Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_matrix = data.corr()\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax = sns.heatmap(corr_matrix,\n",
    "                 annot=True,\n",
    "                 linewidths=0.5,\n",
    "                 fmt=\".2f\",\n",
    "                 cmap=\"YlGnBu\");\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:44.709806Z",
     "start_time": "2020-05-28T01:52:44.584626Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_matrix['target'].iloc[:-1].plot(kind='bar', grid=True, figsize=(8, 4), \\\n",
    "                                                    title=\"Correlation with target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造虚拟变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:44.738724Z",
     "start_time": "2020-05-28T01:52:44.710765Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dummies(data, class_vars):\n",
    "    tmp_data = data.copy(deep = True)\n",
    "    for key in class_vars:\n",
    "        tmp_data = pd.get_dummies(tmp_data, columns = [key])\n",
    "    return tmp_data\n",
    "\n",
    "df_dummies = get_dummies(data, class_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:44.823971Z",
     "start_time": "2020-05-28T01:52:44.739688Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dummies.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-26T16:29:19.530335Z",
     "start_time": "2020-05-26T16:29:19.514416Z"
    }
   },
   "source": [
    "### 标准化数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:44.915239Z",
     "start_time": "2020-05-28T01:52:44.824968Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df_dummies.drop(columns=['target'])\n",
    "y = df_dummies['target']\n",
    "\n",
    "sc = StandardScaler()\n",
    "X[continue_vars] = sc.fit_transform(X[continue_vars])\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:44.923252Z",
     "start_time": "2020-05-28T01:52:44.916236Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n",
    "### 交叉验证选择最优参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:44.936183Z",
     "start_time": "2020-05-28T01:52:44.924215Z"
    }
   },
   "outputs": [],
   "source": [
    "class EstimatorSelectionHelper:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "        self.best = {}\n",
    "\n",
    "    def fit(self, X, y, cv=3, n_jobs=3, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, refit=refit,\n",
    "                              return_train_score=True)\n",
    "            gs.fit(X,y)\n",
    "            self.best[key] = {'score':gs.best_score_, 'params':gs.best_params_}\n",
    "            self.grid_searches[key] = gs    \n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                 'estimator': key,\n",
    "                 'min_score': min(scores),\n",
    "                 'max_score': max(scores),\n",
    "                 'mean_score': np.mean(scores),\n",
    "                 'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params,**d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            print(k)\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]        \n",
    "                scores.append(r.reshape(len(params),1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params,all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "\n",
    "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "\n",
    "        return df[columns]\n",
    "    def best_params(self):\n",
    "        return self.best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:51.466569Z",
     "start_time": "2020-05-28T01:52:44.937180Z"
    }
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'rf':RandomForestClassifier(),\n",
    "    'gbdt':GradientBoostingClassifier(),\n",
    "    'ada':AdaBoostClassifier(),\n",
    "    'xgb':XGBClassifier(),\n",
    "    'svm':SVC(),\n",
    "    'lr':LogisticRegression(),\n",
    "    'knn':KNeighborsClassifier(),\n",
    "    'dt': DecisionTreeClassifier(),\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'rf':{'n_estimators' : [16, 32,64], \"max_depth\" : [2,4,6]},\n",
    "    'gbdt':{\"n_estimators\" : [16, 32,64,96], \"max_depth\" : [2,4,6], \"learning_rate\" : [0.1,0.3,0.9]},\n",
    "    'ada':{\"n_estimators\" : [16, 32,64], \"learning_rate\" : [0.5,1.0]},\n",
    "    'xgb':{\"max_depth\" : [2,4,6], \"learning_rate\" : [0.1,0.3,0.9]},\n",
    "    'svm': [\n",
    "        {'kernel': ['linear'], 'C': [1, 10]},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
    "    ],\n",
    "    'lr':{'C' : [1, 0.5], 'penalty' : ['l1','l2'], 'solver':['liblinear']},\n",
    "    'knn':{'n_neighbors' : [5,10,15]},\n",
    "    'dt':{\"max_depth\" : [2,4,6],}\n",
    "}\n",
    "\n",
    "Helper = EstimatorSelectionHelper(models, params)\n",
    "Helper.fit(X_train, y_train, cv=5)\n",
    "Helper.score_summary(sort_by='mean_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:51.471553Z",
     "start_time": "2020-05-28T01:52:51.467567Z"
    }
   },
   "outputs": [],
   "source": [
    "best = Helper.best_params()\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置最优参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T01:52:51.485921Z",
     "start_time": "2020-05-28T01:52:51.471553Z"
    }
   },
   "outputs": [],
   "source": [
    "best_models = [\n",
    "    ('rf',RandomForestClassifier()),\n",
    "    ('gbdt',GradientBoostingClassifier()),\n",
    "    ('ada',AdaBoostClassifier()),\n",
    "    ('xgb',XGBClassifier()),\n",
    "    ('svm',SVC()),\n",
    "    ('lr',LogisticRegression()),\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "]\n",
    "\n",
    "for item in best_models:\n",
    "    key, clf = item\n",
    "    clf.set_params(**best[key]['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T02:21:45.615337Z",
     "start_time": "2020-05-28T02:21:45.476386Z"
    }
   },
   "outputs": [],
   "source": [
    "vote_hard = VotingClassifier(estimators = best_models , voting = 'hard')\n",
    "vote_hard.fit(X_train, y_train)\n",
    "prediction = vote_hard.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T02:21:48.858075Z",
     "start_time": "2020-05-28T02:21:48.853090Z"
    }
   },
   "outputs": [],
   "source": [
    "correct = (prediction == y_test).sum()\n",
    "accuracy = correct / len(y_test)\n",
    "print(f'accuracy {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 混淆矩阵以及分类结果报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T02:21:50.967188Z",
     "start_time": "2020-05-28T02:21:50.958212Z"
    }
   },
   "outputs": [],
   "source": [
    "cr = classification_report(y_test, prediction)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T02:21:54.254447Z",
     "start_time": "2020-05-28T02:21:54.132772Z"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, prediction)\n",
    "plt.figure(figsize=(7,7))\n",
    "sns.heatmap(cm, annot = True, annot_kws = {'size':15}, cmap = 'PuBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过RF查看特征的重要程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T02:30:43.267316Z",
     "start_time": "2020-05-28T02:30:43.023850Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = best_models[0][1]\n",
    "rf.fit(X_train, y_train)\n",
    "def feature_imp(df, model):\n",
    "    df = df.drop(columns = ['target'])\n",
    "    fi = pd.DataFrame()\n",
    "    fi[\"feature\"] = df.columns\n",
    "    fi[\"importance\"] = model.feature_importances_\n",
    "    return fi.sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "feature_imp(df_dummies, rf).plot(kind='barh', figsize=(12,7), legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 复盘\n",
    "**1.第一个出错的点,就是在画与target相关变量的饼图的时候,并没有考虑将0也算在内,某个条件患心脏病的人数多,并不能认为该条件下患心脏病的人数就高, 因此,直接拿来做为同一个特征是不合理的.**\n",
    "\n",
    "**2.没有只缩放连续型变量,这里应该是个导致结果不好的原因.**\n",
    "\n",
    "**3.归一化与划分数据集的先后顺序问题. 参考知乎上的回答:**\n",
    "\n",
    "1、整体归一化后，再划分。\n",
    "实际上我是从一些数据竞赛中得到一些经验。整体归一化实际上是让你的模型更快地知道了比较稳定的统计量（比如均值），因为一个是部分训练集统计的均值，而另一部分是训练集全集的均值。还有在特征构建上，经常会计算某某字段距离该字段均值（或其他统计量，比如比较稳健的中位数）的差距或者距离。更多样本的均值自然会比较稳定。这样在本地测试集上的效果评价就会过于乐观，或者说我提到的泄露。你也知道，在数据算法竞赛中，线上和本地测试集的优化方向一致性是非常重要的。如果你不严格地做本地测试集，真正把它隔离出来，那在本地优化个半天的结果，传到线上，就会一塌糊涂，也就是过拟合本地的测试集了。另外数据算法竞赛竞争非常激烈，前几名可能都是丝毫分厘之差而已。做好这些细节是有助于提高名次了。当然在实际工程应用中，这些就比较随意和灵活，更讲求实用性。\n",
    "\n",
    "**方案1通常被视为\"data leakage\"原则错误，在训练模型的时候应用了test的信息(如极值、均值方差等)；同时方案1也会使得训练集中各变量不严格服从[0,1]的分布，这和归一化的初衷是相违背的；\n",
    "所以,正确的做法是对训练集进行标准化, 然后用训练集的标准去规范测试集.**\n",
    "\n",
    "**4. 集成树模型可以输出特征的重要性**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288.936px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
