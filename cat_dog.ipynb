{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:07.166850Z",
     "start_time": "2020-06-05T13:19:04.576547Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageStat\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.resnet import resnet18\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "train_bs = 16\n",
    "test_bs = 16\n",
    "lr_init = 0.0001\n",
    "max_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:07.273518Z",
     "start_time": "2020-06-05T13:19:07.168845Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "train_path = '../data/cat_dog/training_set/training_set/'\n",
    "test_path = '../data/cat_dog/test_set/test_set/'\n",
    "\n",
    "train_all = {}\n",
    "test_all = {}\n",
    "\n",
    "for trainable in [True, False]:\n",
    "    if trainable:\n",
    "        for category in ['cats', 'dogs']:\n",
    "            train_all[category] = glob.glob(os.path.join(train_path + category, '*.jpg'))\n",
    "    else:\n",
    "        for category in ['cats', 'dogs']:\n",
    "            test_all[category] = glob.glob(os.path.join(test_path + category, '*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:07.288480Z",
     "start_time": "2020-06-05T13:19:07.276524Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    'train cats: ',len(train_all['cats']),'\\n',\n",
    "    'train dogs:', len(train_all['dogs']),'\\n',\n",
    "    'test cats: ',len(test_all['cats']),'\\n',\n",
    "    'test dogs: ',len(test_all['dogs']),'\\n',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:08.844832Z",
     "start_time": "2020-06-05T13:19:07.291471Z"
    }
   },
   "outputs": [],
   "source": [
    "x, y = [], []\n",
    "Outlier = []\n",
    "for category in ['cats', 'dogs']:\n",
    "    for path in train_all[category]:\n",
    "        img = Image.open(path)\n",
    "        x.append(img.size[0])\n",
    "        y.append(img.size[1])\n",
    "        if img.size[0] >= 600:\n",
    "            Outlier.append(path)\n",
    "print(Outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:09.259017Z",
     "start_time": "2020-06-05T13:19:08.847800Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Height')\n",
    "plt.title('Train Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:09.722591Z",
     "start_time": "2020-06-05T13:19:09.261005Z"
    }
   },
   "outputs": [],
   "source": [
    "# 测试集散点图分布\n",
    "x, y = [], []\n",
    "for category in ['cats', 'dogs']:\n",
    "    for path in test_all[category]:\n",
    "        img = Image.open(path)\n",
    "        x.append(img.size[0])\n",
    "        y.append(img.size[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:09.952355Z",
     "start_time": "2020-06-05T13:19:09.723620Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('Weight')\n",
    "plt.ylabel('Height')\n",
    "plt.title('Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:09.981247Z",
     "start_time": "2020-06-05T13:19:09.955341Z"
    }
   },
   "outputs": [],
   "source": [
    "mapkey = {\n",
    "    'cats':'0',\n",
    "    'dogs':'1',\n",
    "}\n",
    "\n",
    "    \n",
    "def gen_txt(txt_path, img_paths):\n",
    "    \n",
    "    f = open(txt_path, 'w')\n",
    "    for key in img_paths.keys():\n",
    "        label = mapkey[key]\n",
    "        for path in img_paths[key]:\n",
    "            line = path + ' ' + label + '\\n'\n",
    "            f.write(line)\n",
    "\n",
    "gen_txt('../data/cat_dog/train.txt', train_all)\n",
    "gen_txt('../data/cat_dog/test.txt', test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:40.323361Z",
     "start_time": "2020-06-05T13:19:09.984242Z"
    }
   },
   "outputs": [],
   "source": [
    "# 计算训练集的均值和标准差\n",
    "\n",
    "\n",
    "train_paths = train_all['cats'] + train_all['dogs']\n",
    "\n",
    "m_list, s_list = [], []\n",
    "for path in tqdm(train_paths):\n",
    "    img = cv2.imread(path)\n",
    "    img = img / 255.0\n",
    "    m, s = cv2.meanStdDev(img)\n",
    "    m_list.append(m.reshape((3,)))\n",
    "    s_list.append(s.reshape((3,)))\n",
    "m_array = np.array(m_list)\n",
    "s_array = np.array(s_list)\n",
    "m = m_array.mean(axis=0, keepdims=True)\n",
    "s = s_array.mean(axis=0, keepdims=True)\n",
    "# BGR -> RGB\n",
    "print(m[0][::-1])\n",
    "print(s[0][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:40.330344Z",
     "start_time": "2020-06-05T13:19:40.324359Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt_path, transform=None, target_transform=None):\n",
    "        fh = open(txt_path, 'r')\n",
    "        imgs = []\n",
    "        for line in fh:\n",
    "            line = line.rstrip()\n",
    "            words = line.split()\n",
    "            imgs.append((words[0], int(words[1])))\n",
    "\n",
    "        self.imgs = imgs        # 最主要就是要生成这个list， 然后DataLoader中给index，通过getitem读取图片数据\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        img = Image.open(fn).convert('RGB')     # 像素值 0~255，在transfrom.totensor会除以255，使像素值变成 0~1\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)   # 在这里做transform，转为tensor等等\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:40.337324Z",
     "start_time": "2020-06-05T13:19:40.332338Z"
    }
   },
   "outputs": [],
   "source": [
    "normMean = [0.48827705, 0.45510637, 0.41741   ]\n",
    "normStd = [0.22971935, 0.22475049, 0.22525084]\n",
    "normTransform = transforms.Normalize(normMean, normStd)\n",
    "trainTransform = transforms.Compose([\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize((280,280)),\n",
    "#     transforms.RandomCrop((224,224), padding=28),\n",
    "#     transforms.RandomRotation(degrees = 30),\n",
    "    transforms.ToTensor(),\n",
    "    normTransform,\n",
    "])\n",
    "\n",
    "testTransform = transforms.Compose([\n",
    "    transforms.Resize((280,280)),\n",
    "    transforms.ToTensor(),\n",
    "    normTransform,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:40.356307Z",
     "start_time": "2020-06-05T13:19:40.339322Z"
    }
   },
   "outputs": [],
   "source": [
    "train_txt_path = '../data/cat_dog/train.txt'\n",
    "test_txt_path = '../data/cat_dog/test.txt'\n",
    "\n",
    "train_data = MyDataset(txt_path=train_txt_path, transform=trainTransform)\n",
    "test_data = MyDataset(txt_path=test_txt_path, transform=testTransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:40.368395Z",
     "start_time": "2020-06-05T13:19:40.357310Z"
    }
   },
   "outputs": [],
   "source": [
    "for image,label in test_data:\n",
    "    print(image.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:40.374694Z",
     "start_time": "2020-06-05T13:19:40.370719Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=train_bs, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=test_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:41.636767Z",
     "start_time": "2020-06-05T13:19:40.375692Z"
    }
   },
   "outputs": [],
   "source": [
    "def image_convert(img):\n",
    "    img = img.clone().cpu().numpy()\n",
    "    img = img.transpose(1,2,0)\n",
    "    normStd = [0.22971935, 0.22475049, 0.22525084]\n",
    "    normMean = [0.48827705, 0.45510637, 0.41741   ]\n",
    "    img = img*normStd + normMean\n",
    "    return img\n",
    "\n",
    "\n",
    "def plot_10():\n",
    "        iter_ = iter(train_loader)\n",
    "        images,labels = next(iter_)\n",
    "        an_ = {'0':'cat','1':'dog'}\n",
    "        \n",
    "        plt.figure(figsize=(20,10))\n",
    "        for idx in range(10):\n",
    "            plt.subplot(2,5,idx+1)\n",
    "            img = image_convert(images[idx])\n",
    "            label = labels[idx]\n",
    "            plt.imshow(img)\n",
    "            plt.title(an_[str(label.numpy())])\n",
    "        plt.show()\n",
    "\n",
    "plot_10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:41.642716Z",
     "start_time": "2020-06-05T13:19:41.637778Z"
    }
   },
   "outputs": [],
   "source": [
    "class fc_part(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(512,120)\n",
    "        self.fc2 = nn.Linear(120, 2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:44.186476Z",
     "start_time": "2020-06-05T13:19:41.643714Z"
    }
   },
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=True).to(device)\n",
    "model.fc = fc_part().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:47.532773Z",
     "start_time": "2020-06-05T13:19:44.217381Z"
    }
   },
   "outputs": [],
   "source": [
    "# images, labels = next(iter(train_loader))\n",
    "# if torch.cuda.is_available():\n",
    "#     images = images.to(device)\n",
    "# grid = torchvision.utils.make_grid(images)\n",
    "# comment = f'batch_size{train_bs} lr{lr_init}'\n",
    "# tb = SummaryWriter(comment=comment)\n",
    "# tb.add_image('images', grid)\n",
    "# tb.add_graph(model, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:47.555713Z",
     "start_time": "2020-06-05T13:19:47.549730Z"
    }
   },
   "outputs": [],
   "source": [
    "## 按需设置学习率, 因为我们全连接层前面的权重全是预训练加载来的权重, 因此Finetune一下就行\n",
    "\n",
    "ignored_params = list(map(id, model.fc.parameters()))\n",
    "base_params = filter(lambda p: id(p) not in ignored_params, model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:19:47.569700Z",
     "start_time": "2020-06-05T13:19:47.561697Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([\n",
    "    {'params': base_params},\n",
    "    {'params': model.fc.parameters(), 'lr': lr_init*10}],  lr_init, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()                                                   # 选择损失函数\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)     # 设置学习率下降策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:37:27.834611Z",
     "start_time": "2020-06-05T13:19:47.574699Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, max_epoch+1):\n",
    "\n",
    "    train_loss = 0.0    # 记录一个epoch的loss之和\n",
    "    train_correct = 0.0\n",
    "    train_total = 0.0\n",
    "    \n",
    "    scheduler.step()  # 更新学习率\n",
    "    \n",
    "    with tqdm(train_loader, desc = 'Train') as t:\n",
    "        model.train()\n",
    "        for data in t:\n",
    "            # 获取图片和标签\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward, backward, update weights\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model.forward(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 统计预测信息\n",
    "            _, predicted = torch.max(outputs, axis = 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += torch.sum(predicted == labels).item()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            #设置进度条右边显示的信息\n",
    "            t.set_postfix(train_loss = loss.item(), train_accuracy = train_correct / train_total)\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        with tqdm(test_loader, desc = 'Test') as t:\n",
    "            for data in t:                \n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                    \n",
    "                outputs = model.forward(inputs)\n",
    "                loss = F.cross_entropy(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, axis = 1)\n",
    "                test_total += labels.size(0)\n",
    "                test_correct += torch.sum(predicted == labels).item()\n",
    "                t.set_postfix(test_loss = loss.item(), test_accuracy = test_correct / test_total)\n",
    "            \n",
    "#     tb.add_scalar('train_loss', train_loss/train_total, epoch)\n",
    "#     tb.add_scalar('train_accuracy', train_correct/train_total, epoch)\n",
    "#     tb.add_scalar('test_loss', test_loss/test_total, epoch)\n",
    "#     tb.add_scalar('test_accuracy', test_correct / test_total, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T13:37:59.125116Z",
     "start_time": "2020-06-05T13:37:57.290706Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_val_images():\n",
    "\n",
    "    label_dict = ['cat','dog']\n",
    " \n",
    "    iter_ = iter(test_loader)\n",
    "    images,labels = next(iter_)\n",
    "    images = images.to(device)\n",
    "    pred_labels = labels.to(device)\n",
    "\n",
    "    \n",
    "    img_out = model.forward(images)\n",
    "    value, index_val = torch.max(img_out, 1)\n",
    "\n",
    "    # label = label_dict[str(label)]\n",
    "    fig = plt.figure(figsize=(35,9))\n",
    "    for idx in np.arange(10):\n",
    "        ax = fig.add_subplot(2,5,idx+1)\n",
    "        plt.imshow(image_convert(images[idx]))\n",
    "        label = labels[idx]  \n",
    "        pred_label = pred_labels[idx]\n",
    "        ax.set_title('Act {},pred {}'.format(label_dict[label],label_dict[pred_label]))\n",
    "        \n",
    "plot_val_images()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
